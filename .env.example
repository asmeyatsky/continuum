# Application Configuration
APP_NAME=Continuum
APP_VERSION=1.0.0
DEBUG=false

# Logging
LOG_LEVEL=INFO
LOG_FILE=./logs/continuum.log

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4

# Database Configuration
DATABASE_URL=sqlite:///./continuum.db
DATABASE_POOL_SIZE=5

# Knowledge Graph Configuration
KNOWLEDGE_GRAPH_MAX_NODES=10000
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIM=384

# LLM Configuration
# Options: "openai" or "anthropic"
LLM_PROVIDER=openai

# OpenAI Configuration (if LLM_PROVIDER=openai)
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_MODEL=gpt-4o
# OPENAI_MODEL=gpt-4-turbo
# OPENAI_MODEL=gpt-3.5-turbo

# Anthropic Configuration (if LLM_PROVIDER=anthropic)
ANTHROPIC_API_KEY=sk-ant-your-api-key-here
ANTHROPIC_MODEL=claude-3-opus-20240229
# ANTHROPIC_MODEL=claude-3-sonnet-20240229
# ANTHROPIC_MODEL=claude-3-haiku-20240307

# LLM Generation Parameters
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000

# Data Pipeline Configuration
RATE_LIMIT_REQUESTS_PER_SECOND=10
REQUEST_TIMEOUT=30
RETRY_ATTEMPTS=3
RETRY_BACKOFF=1.5

# Content Generation Configuration
MIN_CONTENT_LENGTH=100
MAX_CONTENT_LENGTH=10000
QUALITY_THRESHOLD=0.75

# Performance Configuration
ENABLE_CACHING=true
CACHE_TTL_SECONDS=3600
ASYNC_BATCH_SIZE=10
